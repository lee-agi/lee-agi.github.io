---
{"dg-publish":true,"permalink":"/010-outbox/ai-the-future-of-intelligence-demis-hassabis-co-founder-and-ceo-of-deep-mind-2025-m12/"}
---


## 封面
- 标题：The future of intelligence | Demis Hassabis (Co-founder and CEO of DeepMind)
- 链接：https://www.youtube.com/watch?v=PqVbypvxDto
- 发布日期：2025-12-16
- 总字数：4625
- 预估阅读时长：约 16 分钟
- 生成时间：2025-12-16 19:13:47
- 覆盖时长：00:55:56

## 摘要总结
- Demis 认为通往 AGI 的路径是==“50% scaling、50% innovation”，并强调一致性、系统化思考（reasoning）与在线持续学习仍是关键缺失==。同时他高度看好 ==world models 的进展与多模态==（Gemini 3 等）的收敛。
- 以 AlphaFold 为“root node”范例，DeepMind 正把 ==AI 推向材料、聚变==（与 Commonwealth Fusion 深度合作）、==量子==（error correction codes）等基础科学，并指出==合成数据可缓解数据匮乏，scaling 尚未遇到“墙”==。
- 对社会影响，他预测“这次变革或将比工业革命大10倍且快10倍”，需提前==设计新经济与治理机制==（可能含 UBI、更加直接的民主决策与结果评估），并警惕短期泡沫、长期低估。
- 对安全与治理，Demis主张*在产品化过程中形成负责任的行业压力*，并预判未来2—3年 agent 将更自主、风险更高，需提前进行网络攻防准备和国际协作、制定标准。
- 在计算本体论上，他倾向于==“万物可计算”（模拟）==的立场：或许 ==宇宙万物在合适表述下都可被 Turing machine 建模（Turing machine 的极限是什么？）==，甚至把==“信息”视为宇宙最基本单位==；由此，**高保真大规模模拟**将是理解心智与意识上限的强力工具。

## 全文

### AGI 路径与可计算性（00:00:00 - 00:00:49）
**Demis Hassabis**：你可以把我们的努力理解为一半在 scaling、一半在 innovation。我押注要到达 AGI 两者都必不可少。我一直觉得，如果我们先构建 AGI，用它来模拟心智，再与真实人类心智对比，我们就能看到差异，并可能发现人类心智独特且尚未被复制的部分，可能是 creativity、emotions，或 dreaming。关于 consciousness 的可计算性有很多假说，这又回到 Turing machine 的问题：它的极限是什么？
**Hannah Fry**：所以没有什么是这些计算机器做不到的吗？
**Demis Hassabis**：到目前为止，==还没有人在宇宙中发现任何“不可计算”的东西（non-computable）==。

### 开场与年度回顾（00:00:53 - 00:02:13）
**Hannah Fry**：欢迎来到 Google DeepMind: The Podcast。我是 Hannah Fry。过去一年 AI 异常不凡：重心从大语言模型转向 agentic AI；AI 加速药物发现；多模态进入机器人与无人驾驶……但这期收官我们想问更大的问题：下一阶段的科学与技术问题是什么？欢迎回归的来宾是 Google DeepMind 的 CEO 和联合创始人 Demis Hassabis。
**Demis Hassabis**：很高兴再来。过去一年像把十年进展塞进了一年。对我们来说，模型进步显著。我们刚发布了 Gemini 3，多模态能力等都前进很大。我也尤其兴奋于夏天以来 world models 的进展，等会儿肯定会谈到。

### Root node 问题与科学合作：AlphaFold、材料、聚变、量子（00:02:17 - 00:03:54）
**Hannah Fry**：上次你讲“root node”问题：用 AI 解锁下游价值。你们的进展如何？
**Demis Hassabis**：当然，AlphaFold 是个大“证明点”，AlphaFold 2 都快到五周年了，证明这类 root node 问题可解。我们也在探索材料科学——我很想做室温超导、也想要更好的电池与材料。我们还在做聚变：刚与 Commonwealth Fusion 宣布更深合作（我们之前已合作），他们可能是传统 Tokamak 路线最好的初创，也可能距离可行性最近。我们想加速他们，帮助磁约束等，甚至材料设计。我们也在与 Google 的 quantum AI 团队合作，他们做得很棒；我们用 machine learning 帮他们做 error correction codes，也许未来他们也能帮我们。

### 为什么聚变是 Holy Grail（00:03:56 - 00:05:13）
**Hannah Fry**：若聚变突破，对世界的影响巨大。
**Demis Hassabis**：聚变一直是“holy grail”。当然我也看好太阳能，本质上也是“利用天空中的聚变反应堆”。但如果能做出模块化聚变反应堆，几乎无限、可再生、清洁、低成本的能源将改变一切。这能直接帮助能源、污染与气候危机。且若能源极其廉价干净，很多事都可行，例如海水淡化普及、甚至制备火箭燃料（海水中有氢和氧，分离需要大量能量；若能源廉价清洁，就可以 24/7 连续产出）。

### 数学与一致性：“jagged intelligence”（00:05:13 - 00:07:31）
**Hannah Fry**：AI 在数学上“奥赛夺金 vs 高中题犯错”的悖论为何存在？
**Demis Hassabis**：这非常迷人，也是我们未达 AGI 的核心障碍之一。AI 在 International Maths Olympiad 上能拿金牌，那些题极难；但换个提问方式，它又会在逻辑题上犯低级错，甚至还不能下出“稳定体面”的国际象棋。这说明系统的一致性缺失。有人称它为“jagged intelligence”：在某些维度上像博士生，但在另一些维度连高中都不到，表现参差不齐。原因很多，包括图像 tokenization 时可能没“看清”所有字母，导致计数出错。还有“thinking/推理时间”如何被有效利用、以及调用工具的自检尚不稳定。我们在路上，但也许才走到一半。
- 见解加粗：**通往通用智能，关键在于跨任务的一致性与稳定的推理/自检能力。**

### AlphaGo/AlphaZero 类比与持续学习缺失（00:07:32 - 00:09:28）
**Hannah Fry**：AlphaGo 到 AlphaZero，“去人类经验反而更好”的类比在科学/数学上成立吗？
**Demis Hassabis**：我们现在构建的更像 AlphaGo：foundation models 从互联网吸收几乎所有人类知识并压缩为可泛化的“模型”；但在其上叠加“搜索/思考”层（像 AlphaGo）仍是早期。现阶段瓶颈不是“人类知识的上限”，而是如何可靠地使用这些系统。未来可以做“AlphaZero-like”的自发现知识，但更难。另一个缺失是在线持续学习（continual/online learn）：今天的系统训练-对齐-后训后发布，到了现实世界不会像人类那样持续学习。这是通往 AGI 的关键拼图。

### 科研 vs 商业竞赛：我本想更慢（00:09:28 - 00:12:17）
**Hannah Fry**：你说过“若按我来，会让 AI 在实验室多待一阵，做更多像 AlphaFold 的事，或许甚至先治愈癌症”。我们错过了更慢的路线吗？
**Demis Hassabis**：既有得也有失。那会是更“纯”的科学路线，也是我最初计划：小心翼翼地、一步步分析系统表现与安全，同时分支技术去服务社会（科学与医学），如同 AlphaFold 虽非通用 foundation model，但融合了 transformers 等通用技术与领域技术。现实是，chatbots 在规模上可行，后来演化为能处理图像/视频的 foundation models（如 Gemini），并在商业上很成功。我也一直梦想“终极助理”：提升生产力、保护注意力、帮助进入心流。但这也引发了公司与国家层面的“竞速态势”，让严谨科研更难。好处是资源大幅涌入、公众几乎只落后前沿几个月、政府理解更快。

### Scaling 没有“墙”：合成数据与研究优势（00:12:41 - 00:15:16）
**Hannah Fry**：不是说 scaling 会撞墙、数据会枯竭吗？Gemini 3 仍在一系列基准上领先，这是怎么做到的？
**Demis Hassabis**：我们没看到“墙”。确实有“收益递减”，但不是“要么指数、要么归零”的二值观。Gemini 3 这次的显著提升仍值得投入。数据稀缺可用合成数据规避，尤其在 coding、math 这些可校验领域，能产生“近乎无限”的高质量数据。我们的优势在于“research-first”的传统与深厚研究队伍——从 Transformers、AlphaGo/AlphaZero 到现在，多数关键突破来自 Google/DeepMind。再叠加世界级工程与基础设施（TPUs），越是地形艰难越能凸显“科研+工程+算力”的组合优势。
- 见解加粗：**在可校验领域用合成数据延展 scaling，是穿越“数据枯竭焦虑”的务实路径。**

### 世界模型要物理正确：控制“hallucinations”（00:23:20 - 00:25:45）
**Hannah Fry**：这些生成世界如何确保物理真实，不至于“看起来像，但其实错”？
**Demis Hassabis**：这就是“hallucinations”（幻觉）问题。有时受控的“幻觉”对创意是好事，但训练 sim agent 时你不想“物理学被脑补”。我们在做“物理基准”：用高精物理的游戏引擎，做类似 A-level 物理实验的小视频（小球滚落、不同轨道速度、拆解牛顿三定律），看 VO、Genie 等是否“100%内化物理”。现在它们“肉眼逼真”，但还没到机器人可依赖的精度。下一步是大量“ground truth”的简单物理视频（单摆、双摆、三体等）。好消息是，VO 在反射与液体上的处理已“肉眼惊人”，现在要超越“肉眼”，经得起真正的物理实验检验。
- 见解加粗：**把“可控幻觉”与“物理准确”剥离，是 world models 落地机器人前的关键门槛。**

### 在模拟中演化、社会与监控（00:25:46 - 00:28:24）
**Hannah Fry**：你是否好奇在模拟中运行“演化中的 agent”？
**Demis Hassabis**：我很想做——不仅生物演化，还包含社会动力学（想起 Santa Fe 的格子社会实验）。放对激励，让 agent 跑久了会自发涌现市场、银行等复杂结构。这些工具将帮助我们理解生命与意识的起源。模拟的威力在于可控、可重复地改变初始条件做统计学意义上的“百万次实验”。当然要在安全沙箱中运行、最好 air-gap，并用其他 AI 系统 24/7 监控、标注“有趣或可疑”的事件。

### AI 泡沫？短期过热、长期低估（00:28:25 - 00:31:55）
**Hannah Fry**：如果 AI 泡沫破裂会怎样？
**Demis Hassabis**：我仍认为“短期过度炒作、长期被低估”。生态里某些部分像“泡沫”（比如毫无产品就拿到夸张估值的种子轮），但大厂估值后面有真业务。面向划时代技术，市场常经历“对早期的低估”与“后期的过度反应”。无论是否回调，我们都处于强势位：自有算力栈（TPUs）、庞大产品生态可内嵌 AI（Search 的 AI Overviews/AI mode、Workspace/Email、YouTube、Chrome），还有成长中的 Gemini app 与“universal assistant”。过去一年我们已把“给既有生态加 AI 增强”的效率打磨得很高。

### 避免回音室：Gemini 3 Persona 的设计（00:31:58 - 00:34:30）
**Hannah Fry**：如何避免“最大化用户黏性”重蹈社交媒体覆辙，且防止“与 chatbot 对话的自我回音室”？
**Demis Hassabis**：我们为 Gemini 3 打造了“温暖、乐于助人、轻松但简洁”的科学人格，会在必要时友善地“反驳/纠偏”，而不是谄媚（sycophantic）地迎合“地平说”等。要平衡“支持用户头脑风暴”与“避免错误强化”。我们在发展“persona 科学”，衡量幽默、真实感、简洁性等，并提供“基线人格+个性化偏好”的双层结构，但基线要遵循科学方法，便于大家用于科学、医学、健康等严肃场景。
- 见解加粗：**把“反思性纠偏”写入大模型的人格，是破除一人一室回音的关键设计点。**

### 逼近 AGI：多模态与 world models 的收敛（00:34:30 - 00:36:19）
**Hannah Fry**：什么最接近你心中的 AGI？
**Demis Hassabis**：Gemini 3 很能打；上周我们还发布了图像生成工具的“高级版”系统 Nano Banana Pro（内含 Gemini）。它不仅看懂图像，还“语义理解”图像在讲什么；比如给它一张复平面的图，它能把各部分标注清楚，甚至拆解结构去可视化；对材质、部件理解也很深入，文本渲染也很准。这几乎是“图像领域的通用系统”。再叠加 world models 的 Genie、Simmer 等进步，下一步要把这些项目收束成“一体化大模型”，那或许就是“proto-AGI”的候选。

### 工业革命的镜鉴：10倍大、10倍快（00:36:19 - 00:38:34）
**Hannah Fry**：我们能从工业革命吸取什么以缓解冲击？
**Demis Hassabis**：从纺织起家、打孔卡到早期计算，再到蒸汽机；它带来巨大红利（儿童死亡率下降、现代医学与卫生、工作与生活分离），也有长期的失配与新的组织（工会等）来再平衡。总体没人愿意回到工业化之前。但这次可能“更大且更快”：也许规模 10 倍，速度 10 倍（像十年而非百年）。
- 见解加粗：**这次技术迁徙若“十倍大十倍快”，前置设计再分配机制与就业转型就不是可选项。**

### 后 AGI 经济与目的感（00:38:39 - 00:41:17）
**Hannah Fry**：后 AGI 的经济与社会要如何重构？
**Demis Hassabis**：我们和 Shane Legg 正在系统思考。可能需要全新的经济模型，以确保广泛分配，比如 UBI 可能是其中一环，但未必完整。我也在和经济学朋友头脑风暴“更直接的民主”——用有限 credits 在社区层面决策（游乐场？球场？教室？），并测量结果；长期“好决策者”在下一轮有更多影响力。若聚变带来后稀缺，金钱、工作的意义与“人生目的感”也会变化，哲学问题会与经济问题交织。

### 国际协作、“告警时刻”与标准（00:41:17 - 00:44:48）
**Hannah Fry**：是否担心社会准备不足？会不会需要“事件”来唤醒协作？
**Demis Hassabis**：我确实担心。按我们“五到十年”的时间尺度，构建新机构已不算宽裕。当前机构零散且影响力不足，地缘紧张让协作更难。也许随着系统更强、能力更可感（因产品化），政府会更快反应。我希望不需要负面事件来催化。多数大实验室在尽责，且商业压力会“反向激励”责任：企业客户会要求 agent 的边界与护栏，“牛仔式”作风拿不到生意。当然仍会有“流氓行为”（国家/组织/开源叠代），中型事故或许会成为“国际标准与协作”的警钟。

### 可计算性再论：Turing machine 与信息本体论（00:44:48 - 00:49:05）
**Hannah Fry**：ASI 阶段，会有机器永远做不到的人类能力吗？
**Demis Hassabis**：==我的人生核心问题之一是 Turing machine 的极限==。做出 AGI、用它模拟心智，再和真实心智对比，或许能看出人类剩余的独特性（creativity、emotions、dreaming……）。我们一直在把 Turing machine 能做的事推到极限（连蛋白折叠、围棋都做了）。我不确定极限在哪，或许根本没有。量子朋友会说量子系统需要量机，但我不确定 —— 也许只需“量子系统的数据”，就可做“经典模拟”。这又回到心智：它是纯经典吗？若如 Penrose 所言==意识涉及量子效应，那经典机器就无解、得等量子计算==；若不是，那也许宇宙万物在合适表述下都可被 Turing machine 建模。到目前为止，没人发现宇宙中“不可计算”的现象。我也受 Kant 影响很深——现实是“心灵的建构”。归根到底，光、热、触觉等都是输入到我们的感知系统的信息，生物本质上是信息处理系统。我甚至在业余琢磨把“信息”而非能量/物质作为宇宙最基本单位的物理理论。若能高保真地“模拟它”，在某种意义上就“理解了它”。
- 见解加粗：**“信息是最基本单位”与“一切可被 Turing machine 模拟”的立场，是强非共识但极具解释力的研究假设。**

### 个人层面：兴奋、焦虑与创意的权衡（00:49:05 - 00:53:13）
**Hannah Fry**：站在前沿的情绪负担会让你感到孤独吗？
**Demis Hassabis**：我经常睡不好：一方面兴奋，因为我们几乎每月都在前沿发现新东西；另一方面，我们也最理解十年尺度上将要发生的“巨大改变”，包括“何谓人类”的哲学追问。AlphaGo 当年也是苦乐参半——破解了一个美丽的谜。到语言、影像、创意工具，电影导演们一方面用它们把原型期缩短 10 倍，另一方面也担心部分创意技能被替代。人类是“制工具”的动物，这样的权衡其实是整个人类史的主线。

### 行业同侪与竞争（00:53:13 - 00:53:13）
**Hannah Fry**：AI 领袖之间有“同袍感”还是被竞争撕裂？
**Demis Hassabis**：我们基本都认识、相处不错（有些人与彼此关系一般）。竞争极其激烈，老牌 VC 都说比“互联网泡沫时代”还要凶。但==我很享受竞争；同时大家都应看到“公司胜负之上”的更大赌注==。

### Agent 两三年内的风险与防御（00:53:15 - 00:54:29）
**Hannah Fry**：未来十年，你个人最担忧的节点？
**Demis Hassabis**：今天的系统是“被动”的：人类提任务，模型给答案。接下来是“agent based systems”，未来两三年会出现“可靠而强”的 agent，它们会更自主，因而风险上升。我们已在为“数百万 agent 在线游走”的世界做网络防御准备。
- 见解加粗：**agent 的“更强+更自律”是生产力跃迁与安全风险同时大增的分水岭。**

### 使命：安全引导 AGI，之后放个假（00:54:29 - 00:55:29）
**Hannah Fry**：有朝一日你能“功成身退”吗？
**Demis Hassabis**：我确实需要个“sabbatical”（哪怕一周）。我的使命是“**帮助世界把 AGI 安全送达全人类**”，等到那一步，我人生使命的核心就完成了。当然之后还有 superintelligence、后 AGI 的经济与社会，我也愿意贡献。但等到那时，我会去好好放个应得的长假。

### 节目收尾（00:55:30 - 00:55:56）
**Hannah Fry**：这一季到此结束。订阅我们，等 2026 年回归；其间欢迎回听今年涵盖的无人驾驶、机器人、world models、药物发现等诸多话题。再见。

## 欢迎交流与合作
目前主要兴趣是探索agent的落地，想进一步交流可加微信（cleezhang），一些[自我介绍](https://lee-agi.github.io/85ed64eda0/)。

> 本文发表于 2025-12-17_周三。
